{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prediction using forward propagation Method .ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMElYfBEOiEUyOaNLJcudVP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akashf/DataScience-Notes/blob/master/Prediction_using_forward_propagation_Method_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7DgAC_RzXms",
        "colab_type": "text"
      },
      "source": [
        "This is first notbook for Artifical Intelligence technique Forwarod Propagation :\n",
        "\n",
        "\n",
        "all deep learning libraries have the entire training and prediction processes implemented, and so in practice you wouldn't really need to build a neural network from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODmEDzZ20Bav",
        "colab_type": "text"
      },
      "source": [
        "**How a neural network** makes predictions through the forward propagation process. Here is a neural network that takes two inputs, has one hidden layer with two nodes, and an output layer with one node.\n",
        "![Neueal Network Forward Propagation Calculation Technique ](http://cocl.us/neural_network_example)\n",
        "\n",
        "X, is the input value\n",
        "W, is the weight of the input x\n",
        "b, is the bias like constent we add \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gifXmUqN1wBo",
        "colab_type": "text"
      },
      "source": [
        "### **Bias is like the intercept** \n",
        "added in a linear equation. It is an additional parameter in the Neural Network which is used to adjust the output along with the weighted sum of the inputs to the neuron. Thus, Bias is a constant which helps the model in a way that it can fit best for the given data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jDGtVUw2bz5",
        "colab_type": "text"
      },
      "source": [
        "Let's start by randomly initializing the weights and the biases in the network. We have 6 weights and 3 biases, one for each node in the hidden layer as well as for each node in the output layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WQ8hibV1zXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "weights = np.around(np.random.uniform(size = 6), decimals = 2)\n",
        "biases = np.around(np.random.uniform(size = 3), decimals = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCHScYkv9FnC",
        "colab_type": "text"
      },
      "source": [
        "Printing the weights and biases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPEU_HUm8zuH",
        "colab_type": "code",
        "outputId": "e6a7230c-167f-48b4-b7b4-2736c4f6d7ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(weights)\n",
        "print(biases)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.92 0.4  0.38 0.81 0.41 0.48]\n",
            "[0.86 0.43 0.68]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj8lXddh9hlw",
        "colab_type": "text"
      },
      "source": [
        "Now that we have the weights and the biases defined for the network, let's compute the output for a given input, $x_1$ and $x_2$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW4mXBXo9lzx",
        "colab_type": "code",
        "outputId": "d22806b5-511a-4da3-efe2-bde7332a6a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x1 = 0.5\n",
        "x2 = 0.84\n",
        "print('x1 is {} and x2 is {}'.format(x1,x2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x1 is 0.5 and x2 is 0.84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfldNKvrAvzt",
        "colab_type": "text"
      },
      "source": [
        "Let's start by computing the wighted sum of the inputs, $z_{1, 1}$, at the first node of the hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXinm80i-Rge",
        "colab_type": "code",
        "outputId": "828ade0d-58b9-4227-8104-9ef90218bcf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z_11 = x1*weights[0]+x2*weights[1]+biases[0]\n",
        "print('The weighted sum of the inputs at the first node in the hidden layer is {}'.format(z_11))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The weighted sum of the inputs at the first node in the hidden layer is 1.6560000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBM_OmC_Bn37",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Next, let's compute the weighted sum of the inputs, $z_{1, 2}$, at the second node of the hidden layer. Assign the value to **z_12**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPGOmz9FBRta",
        "colab_type": "code",
        "outputId": "bd92e491-4aeb-4b1d-af7e-383751b0f208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z_12 = x1*weights[2]+x2*weights[3]+ biases[1]\n",
        "print('The weighted sum of the inputs at the second node in hidden layer is {}'.format(np.around(z_12, decimals = 4)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The weighted sum of the inputs at the second node in hidden layer is 1.3004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq1DsliIHWHK",
        "colab_type": "text"
      },
      "source": [
        "Next, assuming a sigmoid activation function, let's compute the activation of the first node, $a_{1, 1}$, in the hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k75In_QmHXCw",
        "colab_type": "code",
        "outputId": "1c3b19a1-3115-4f9b-9974-9c355fea42f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a11 = 1.0/(1.0+(np.exp(-z_11)))\n",
        "a11\n",
        "print('The Activation Funciton of First node of hidden layer A11 is {}: '.format(np.around(a11, decimals=4)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Activation Funciton of First node of hidden layer A11 is 0.8397: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AScCdPDH3Ab",
        "colab_type": "code",
        "outputId": "0ee1a6bf-e04a-4e2d-bba8-d5b2656f7167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "a12 = 1.0/(1.0+(np.exp(-z_12)))\n",
        "print('The Activation Funciton of Second node of hidden layer A12 is {}: '.format(np.around(a12, decimals=4)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Activation Funciton of Second node of hidden layer A12 is 0.7859: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON1KA1bMIcMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9U_yi1ciRfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miP8oxS7iR3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}